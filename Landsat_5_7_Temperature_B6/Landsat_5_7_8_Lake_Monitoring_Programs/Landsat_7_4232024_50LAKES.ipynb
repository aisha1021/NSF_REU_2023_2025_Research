{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9105b708-cf78-4f0c-8d90-63d21df775cd",
   "metadata": {},
   "source": [
    "Landsat 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad754f6c-2ed0-49f6-8496-2a0941e72ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "# ee.Authenticate()\n",
    "\n",
    "ALTM_50_LAKES = ee.FeatureCollection('projects/ee-mazarderakhsh/assets/ALAP-ALTM-195-centroids') \\\n",
    "    .filter(ee.Filter.gte('Field1', 150)) \\\n",
    "    .filter(ee.Filter.lte('Field1', 199))  # pick only ALTM lakes\n",
    "\n",
    "# Convert the lakes FeatureCollection to a List\n",
    "lakesList = ALTM_50_LAKES.toList(ALTM_50_LAKES.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688f7ed7-4c3b-4619-a0db-d899365c7daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_SMP</th>\n",
       "      <th>temp_satellite</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>Windfall Pond</td>\n",
       "      <td>-74.828821</td>\n",
       "      <td>43.805388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187</td>\n",
       "      <td>Queer Lake</td>\n",
       "      <td>-74.799690</td>\n",
       "      <td>43.811038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12773</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195</td>\n",
       "      <td>West Pond</td>\n",
       "      <td>-74.881100</td>\n",
       "      <td>43.810806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22519</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171</td>\n",
       "      <td>Jockeybush Lake</td>\n",
       "      <td>-74.594290</td>\n",
       "      <td>43.303249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189</td>\n",
       "      <td>Sagamore Lake</td>\n",
       "      <td>-74.619377</td>\n",
       "      <td>43.767687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16240</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>17.412764</td>\n",
       "      <td>199</td>\n",
       "      <td>Woods Lake</td>\n",
       "      <td>-74.952392</td>\n",
       "      <td>43.870121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15571</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>Lake Colden</td>\n",
       "      <td>-73.979612</td>\n",
       "      <td>44.122702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159</td>\n",
       "      <td>Avalanche Lake</td>\n",
       "      <td>-73.966783</td>\n",
       "      <td>44.132869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20028</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183</td>\n",
       "      <td>Nate Pond</td>\n",
       "      <td>-74.090528</td>\n",
       "      <td>43.857497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20878</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196</td>\n",
       "      <td>Willis Lake</td>\n",
       "      <td>-74.242343</td>\n",
       "      <td>43.369172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22944 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE_SMP  temp_satellite  SITE_ID        SITE_NAME        Lon  \\\n",
       "0      1999-07-05             NaN      198    Windfall Pond -74.828821   \n",
       "6215   1999-07-05             NaN      187       Queer Lake -74.799690   \n",
       "12773  1999-07-05             NaN      195        West Pond -74.881100   \n",
       "22519  1999-07-05             NaN      171  Jockeybush Lake -74.594290   \n",
       "2877   1999-07-05             NaN      189    Sagamore Lake -74.619377   \n",
       "...           ...             ...      ...              ...        ...   \n",
       "16240  2023-10-03       17.412764      199       Woods Lake -74.952392   \n",
       "15571  2023-10-15             NaN      172      Lake Colden -73.979612   \n",
       "10873  2023-10-15             NaN      159   Avalanche Lake -73.966783   \n",
       "20028  2023-10-15             NaN      183        Nate Pond -74.090528   \n",
       "20878  2023-10-15             NaN      196      Willis Lake -74.242343   \n",
       "\n",
       "             Lat  \n",
       "0      43.805388  \n",
       "6215   43.811038  \n",
       "12773  43.810806  \n",
       "22519  43.303249  \n",
       "2877   43.767687  \n",
       "...          ...  \n",
       "16240  43.870121  \n",
       "15571  44.122702  \n",
       "10873  44.132869  \n",
       "20028  43.857497  \n",
       "20878  43.369172  \n",
       "\n",
       "[22944 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ee\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "# Define the Landsat 5 bands and their corresponding standard names\n",
    "LC5_BANDS = ['ST_B6']\n",
    "LC7_BANDS = ['ST_B6']\n",
    "STD_NAMES = ['temp_satellite']\n",
    "\n",
    "\n",
    "# all_lakes=ee.FeatureCollection('projects/ee-mazarderakhsh/assets/ALAP-ALTM-Lakes-195')\n",
    "\n",
    "def maskL457sr(image):\n",
    "    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n",
    "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
    "    waterMask = image.select('QA_PIXEL').eq(5440).Or(image.select('QA_PIXEL').eq(5504))\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBand = image.select('ST_B6').multiply(0.00341802).add(-124.15)\n",
    "    return image.addBands(opticalBands, None, True).addBands(thermalBand, None, True).updateMask(qaMask).updateMask(saturationMask).updateMask(waterMask)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to compute the mean reflectance values for the specified bands within the region of interest (lake)\n",
    "def reflectance(img, lake):\n",
    "    reflectance_values = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=lake, scale=30).select(STD_NAMES)\n",
    "    return img.set('DATE_SMP', img.date().format()).set('reflectance', reflectance_values)\n",
    "\n",
    "# Initialize an empty list to store the dataframes for each lake\n",
    "dfs = []\n",
    "\n",
    "\n",
    "\n",
    "# Filter out rows with empty latitude or longitude values\n",
    "# df_coord_filtered = df_coord[(df_coord['Lat'].notnull()) & (df_coord['Lon'].notnull())]\n",
    "\n",
    "# Loop through each lake name and retrieve Landsat 5 imagery for that lake\n",
    "for i in range(lakesList.size().getInfo()):\n",
    "    lake = ee.Feature(lakesList.get(i))\n",
    "    lat = ee.Number(lake.geometry().coordinates().get(1))\n",
    "    lon = ee.Number(lake.geometry().coordinates().get(0))\n",
    "    lake_point = ee.Geometry.Point([lon, lat]).buffer(90)\n",
    "    lakeName = ee.String(lake.get('NAME')).getInfo()\n",
    "    lakeID = ee.String(lake.get('Field1')).getInfo()\n",
    "\n",
    "    lat_value = float(ee.Number(lake.geometry().coordinates().get(1)).getInfo())\n",
    "    lon_value = float(ee.Number(lake.geometry().coordinates().get(0)).getInfo())\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "    # Retrieve Landsat 7 imagery for the specific lake\n",
    "    l7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
    "        .filter(ee.Filter.calendarRange(1, 12, 'month')) \\\n",
    "        .filterBounds(lake_point) \\\n",
    "        .filter(ee.Filter.lt('CLOUD_COVER', 50)) \\\n",
    "        .map(maskL457sr) \\\n",
    "        .select(LC7_BANDS, STD_NAMES)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    # Map the reflectance function over the Landsat 5 ImageCollection for the specific lake\n",
    "    map_reflectance = l7.map(lambda img: reflectance(img, lake_point))\n",
    "\n",
    "    # Reduce the mapped image collection to get reflectance values for the specific lake\n",
    "    list_reflectance = map_reflectance.reduceColumns(ee.Reducer.toList(2), ['DATE_SMP', 'reflectance']).values().get(0)\n",
    "\n",
    "    # Convert the results to a pandas DataFrame\n",
    "    df_reflectance = pd.DataFrame(list_reflectance.getInfo(), columns=['DATE_SMP', 'reflectance'])\n",
    "    df_reflectance['DATE_SMP'] = pd.to_datetime(df_reflectance['DATE_SMP'])\n",
    "    df_reflectance['DATE_SMP'] = df_reflectance['DATE_SMP'].dt.date\n",
    "    df_reflectance['reflectance'] = df_reflectance['reflectance'].apply(lambda x: {k: v for k, v in x.items() if v is not None})\n",
    "\n",
    "    # Unpack the 'reflectance' dictionary and create separate columns for each band\n",
    "    df_reflectance = pd.concat([df_reflectance.drop('reflectance', axis=1),\n",
    "                                df_reflectance['reflectance'].apply(pd.Series).astype('float64', errors='ignore')], axis=1)\n",
    "    \n",
    "    df_reflectance['SITE_ID'] = lakeID\n",
    "    df_reflectance['SITE_NAME'] = lakeName\n",
    "    df_reflectance['Lon'] = lon_value\n",
    "    df_reflectance['Lat'] = lat_value\n",
    "\n",
    "    # Add the DataFrame to the list\n",
    "    dfs.append(df_reflectance)\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df_all_lakes_Landsat_7 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by 'DATE_SMP' in ascending order\n",
    "df_all_lakes_Landsat_7.sort_values(by='DATE_SMP', inplace=True)\n",
    "\n",
    "# df_all_lakes.dropna(inplace=True)\n",
    "df_all_lakes_Landsat_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f76bd60-7965-4ae8-ab42-3fee78988299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_17404\\2690047828.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7.dropna(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_SMP</th>\n",
       "      <th>temp_satellite</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20879</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>20.801359</td>\n",
       "      <td>196</td>\n",
       "      <td>Willis Lake</td>\n",
       "      <td>-74.242343</td>\n",
       "      <td>43.369172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>18.924134</td>\n",
       "      <td>156</td>\n",
       "      <td>Rondaxe, Lake</td>\n",
       "      <td>-74.901830</td>\n",
       "      <td>43.766425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16891</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>15.981304</td>\n",
       "      <td>167</td>\n",
       "      <td>G Lake</td>\n",
       "      <td>-74.632893</td>\n",
       "      <td>43.413879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>17.839811</td>\n",
       "      <td>170</td>\n",
       "      <td>Indian Lake</td>\n",
       "      <td>-74.755483</td>\n",
       "      <td>43.617250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20452</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>19.362261</td>\n",
       "      <td>185</td>\n",
       "      <td>Otter Lake</td>\n",
       "      <td>-74.499173</td>\n",
       "      <td>43.188512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>16.863695</td>\n",
       "      <td>181</td>\n",
       "      <td>Middle Pond</td>\n",
       "      <td>-74.378613</td>\n",
       "      <td>44.339499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>15.528493</td>\n",
       "      <td>154</td>\n",
       "      <td>Copperas Pond</td>\n",
       "      <td>-74.376174</td>\n",
       "      <td>44.313918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17317</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>17.338340</td>\n",
       "      <td>167</td>\n",
       "      <td>G Lake</td>\n",
       "      <td>-74.632893</td>\n",
       "      <td>43.413879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18356</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>17.938355</td>\n",
       "      <td>182</td>\n",
       "      <td>Middle Settlement Lake</td>\n",
       "      <td>-75.097268</td>\n",
       "      <td>43.685064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9282</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>17.361148</td>\n",
       "      <td>176</td>\n",
       "      <td>Little Simon Pond</td>\n",
       "      <td>-74.443305</td>\n",
       "      <td>44.154701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9752 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE_SMP  temp_satellite  SITE_ID               SITE_NAME        Lon  \\\n",
       "20879  1999-07-05       20.801359      196             Willis Lake -74.242343   \n",
       "5136   1999-07-05       18.924134      156           Rondaxe, Lake -74.901830   \n",
       "16891  1999-07-05       15.981304      167                  G Lake -74.632893   \n",
       "16465  1999-07-05       17.839811      170             Indian Lake -74.755483   \n",
       "20452  1999-07-05       19.362261      185              Otter Lake -74.499173   \n",
       "...           ...             ...      ...                     ...        ...   \n",
       "1106   2023-10-03       16.863695      181             Middle Pond -74.378613   \n",
       "13878  2023-10-03       15.528493      154           Copperas Pond -74.376174   \n",
       "17317  2023-10-03       17.338340      167                  G Lake -74.632893   \n",
       "18356  2023-10-03       17.938355      182  Middle Settlement Lake -75.097268   \n",
       "9282   2023-10-03       17.361148      176       Little Simon Pond -74.443305   \n",
       "\n",
       "             Lat  \n",
       "20879  43.369172  \n",
       "5136   43.766425  \n",
       "16891  43.413879  \n",
       "16465  43.617250  \n",
       "20452  43.188512  \n",
       "...          ...  \n",
       "1106   44.339499  \n",
       "13878  44.313918  \n",
       "17317  43.413879  \n",
       "18356  43.685064  \n",
       "9282   44.154701  \n",
       "\n",
       "[9752 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates from specified columns\n",
    "df_all_lakes_Landsat_7 = df_all_lakes_Landsat_7.drop_duplicates(subset=['DATE_SMP', 'SITE_ID', 'SITE_NAME', 'Lon', 'Lat'])\n",
    "df_all_lakes_Landsat_7.dropna(inplace=True)\n",
    "\n",
    "# Now df_all_lakes_Landsat8 has duplicates removed from the specified columns\n",
    "df_all_lakes_Landsat_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db16a4e-a6ef-4323-9c23-556c9bdb52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully exported to Excel file: Landsat_7_50Lakes_4232024_WaterMask.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the file path for the Excel file\n",
    "excel_file_path = 'Landsat_7_50Lakes_4232024_WaterMask.xlsx'\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "df_all_lakes_Landsat_7.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(\"DataFrame successfully exported to Excel file:\", excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93969593-7cb6-4616-a301-e40fe55f1c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_Annual_4122024_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_17404\\3539793656.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Combine data for June, July, and August\n",
    "    summer_data = lake_data[lake_data['DATE_SMP'].dt.month.isin([1,2,3,4,5,6, 7, 8,9,10,11,12])]\n",
    "    \n",
    "    # Remove NaN or blank values from x_values and corresponding y_values\n",
    "    x_values = summer_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "    y_values = summer_data['temp_satellite'].values\n",
    "    mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "    x_values = x_values[mask]\n",
    "    y_values = y_values[mask]\n",
    "    \n",
    "    # Check if x and y contain more than one distinct value\n",
    "    if len(np.unique(x_values)) > 1:\n",
    "        slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "        \n",
    "        # Check if the trend is significant (p-value < 0.05)\n",
    "        if p_value < 0.05:\n",
    "            slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "            result = {\n",
    "                'Lake_ID': lake_id,\n",
    "                'Lake_name': pond_n,\n",
    "                'Month': 'Annual',\n",
    "                'Slope_per_Decade': slope_per_decade,\n",
    "                'P-value': p_value,\n",
    "                'R-value': r_value,\n",
    "                'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_50_Annual_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_Annual_4122024_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e456b840-54c9-4a9c-b500-02e68037fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_17404\\2935469420.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_SUMMER_4122024_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Combine data for June, July, and August\n",
    "    summer_data = lake_data[lake_data['DATE_SMP'].dt.month.isin([6, 7, 8])]\n",
    "    \n",
    "    # Remove NaN or blank values from x_values and corresponding y_values\n",
    "    x_values = summer_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "    y_values = summer_data['temp_satellite'].values\n",
    "    mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "    x_values = x_values[mask]\n",
    "    y_values = y_values[mask]\n",
    "    \n",
    "    # Check if x and y contain more than one distinct value\n",
    "    if len(np.unique(x_values)) > 1:\n",
    "        slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "        \n",
    "        # Check if the trend is significant (p-value < 0.05)\n",
    "        if p_value < 0.05:\n",
    "            slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "            result = {\n",
    "                'Lake_ID': lake_id,\n",
    "                'Lake_name': pond_n,\n",
    "                'Month': 'June-August',\n",
    "                'Slope_per_Decade': slope_per_decade,\n",
    "                'P-value': p_value,\n",
    "                'R-value': r_value,\n",
    "                'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_50_SUMMER_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_SUMMER_4122024_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344052c4-8bdf-419e-ba83-5fb0cc9790a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_17404\\181647784.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_May_November_4122024_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Combine data for June, July, and August\n",
    "    summer_data = lake_data[lake_data['DATE_SMP'].dt.month.isin([5,6, 7, 8,9,10,11])]\n",
    "    \n",
    "    # Filter out rows with NaN values\n",
    "    summer_data = summer_data.dropna(subset=['temp_satellite'])\n",
    "    \n",
    "    # Check if the data is not empty\n",
    "    if not summer_data.empty:\n",
    "        # Compute the linear regression\n",
    "        x_values = summer_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "        y_values = summer_data['temp_satellite'].values\n",
    "        \n",
    "        # Check if x and y contain more than one value\n",
    "        if len(x_values) > 1:\n",
    "            slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "            \n",
    "            # Check if the trend is significant (p-value < 0.05)\n",
    "            if p_value < 0.05:\n",
    "                slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "                result = {\n",
    "                    'Lake_ID': lake_id,\n",
    "                    'Lake_name': pond_n,\n",
    "                    'Month': 'May-November',\n",
    "                    'Slope_per_Decade': slope_per_decade,\n",
    "                    'P-value': p_value,\n",
    "                    'R-value': r_value,\n",
    "                    'Temp_satellite': y_values.mean()  # Calculate mean temperature\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_50_May_November_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_May_November_4122024_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a8dc3-b2b5-48d1-9dd2-5f2f290cbe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mean temperatures saved to average_mean_temps_landsat7_summer_2009_2011.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_17404\\3663753902.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_all_lakes_Landsat5 is your DataFrame containing Landsat 5 data\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = lake_data['SITE_NAME'].iloc[0]  # Get the lake name\n",
    "    \n",
    "    # Filter data for the specified years and summer months\n",
    "    summer_data_2009_2011 = lake_data[\n",
    "        (lake_data['DATE_SMP'].dt.year >= 2009) & \n",
    "        (lake_data['DATE_SMP'].dt.year <= 2011) & \n",
    "        (lake_data['DATE_SMP'].dt.month.isin([6, 7, 8]))\n",
    "    ]\n",
    "    \n",
    "    # Calculate the average mean temperature for summer\n",
    "    average_mean_temp = summer_data_2009_2011['temp_satellite'].mean()\n",
    "    \n",
    "    # Append the result to the results list\n",
    "    results.append({\n",
    "        'Lake_ID': lake_id,\n",
    "        'Lake_name': pond_n,\n",
    "        'Average_mean_temp': average_mean_temp\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "average_temps_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "average_temps_df.to_csv('average_mean_temps_landsat7_summer_2009_2011_50LAKES_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Average mean temperatures saved to average_mean_temps_landsat7_summer_2009_2011.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "656ee8cb-a664-4948-bcc6-1aec24a9dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_17404\\937599208.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_Monthly_4122024_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Loop over each month\n",
    "    for month in range(1, 13):\n",
    "        month_data = lake_data[lake_data['DATE_SMP'].dt.month == month]\n",
    "\n",
    "        # Remove NaN or blank values from x_values and corresponding y_values\n",
    "        x_values = month_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "        y_values = month_data['temp_satellite'].values\n",
    "        mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "        x_values = x_values[mask]\n",
    "        y_values = y_values[mask]\n",
    "\n",
    "        # Check if x and y contain more than one distinct value\n",
    "        if len(np.unique(x_values)) > 1:\n",
    "            slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "\n",
    "            # Check if the trend is significant (p-value < 0.05)\n",
    "            if p_value < 0.05:\n",
    "                slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "                result = {\n",
    "                    'Lake_ID': lake_id,\n",
    "                    'Lake_name': pond_n,\n",
    "                    'Month': month,\n",
    "                    'Slope_per_Decade': slope_per_decade,\n",
    "                    'P-value': p_value,\n",
    "                    'R-value': r_value,\n",
    "                    'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_50_Monthly_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_Monthly_4122024_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883dabed-3a5d-489f-a1be-88e9141c94fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_17404\\2482162699.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L7_50_Monthly_4232024.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Loop over each month\n",
    "    for month in range(1, 13):\n",
    "        month_data = lake_data[lake_data['DATE_SMP'].dt.month == month]\n",
    "\n",
    "        # Remove NaN or blank values from x_values and corresponding y_values\n",
    "        x_values = month_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "        y_values = month_data['temp_satellite'].values\n",
    "        mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "        x_values = x_values[mask]\n",
    "        y_values = y_values[mask]\n",
    "\n",
    "        # Check if x and y contain more than one distinct value\n",
    "        if len(np.unique(x_values)) > 1:\n",
    "            slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "\n",
    "            slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "            result = {\n",
    "                'Lake_ID': lake_id,\n",
    "                'Lake_name': pond_n,\n",
    "                'Month': month,\n",
    "                'Slope_per_Decade': slope_per_decade,\n",
    "                'P-value': p_value,\n",
    "                'R-value': r_value,\n",
    "                'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_50_Monthly_4232024_RemovePValue_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L7_50_Monthly_4232024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcd348-27a3-4e42-a046-6cd294bcced0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
