{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9105b708-cf78-4f0c-8d90-63d21df775cd",
   "metadata": {},
   "source": [
    "Landsat 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad754f6c-2ed0-49f6-8496-2a0941e72ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "# ee.Authenticate()\n",
    "\n",
    "ALTM_199_LAKES = ee.FeatureCollection('projects/ee-mazarderakhsh/assets/ALAP-ALTM-195-centroids') \\\n",
    "    .filter(ee.Filter.gte('Field1', 1)) \\\n",
    "    .filter(ee.Filter.lte('Field1', 199))  # pick only ALTM lakes\n",
    "\n",
    "# Convert the lakes FeatureCollection to a List\n",
    "lakesList = ALTM_199_LAKES.toList(ALTM_199_LAKES.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688f7ed7-4c3b-4619-a0db-d899365c7daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_SMP</th>\n",
       "      <th>temp_satellite</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>Windfall Pond</td>\n",
       "      <td>-74.828821</td>\n",
       "      <td>43.805388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63735</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>Hewitt Pond</td>\n",
       "      <td>-73.975033</td>\n",
       "      <td>43.870259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63950</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191</td>\n",
       "      <td>South Lake</td>\n",
       "      <td>-74.895066</td>\n",
       "      <td>43.509919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>Penfield Pond</td>\n",
       "      <td>-73.538139</td>\n",
       "      <td>43.911903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39192</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163</td>\n",
       "      <td>Carry Pond</td>\n",
       "      <td>-74.488628</td>\n",
       "      <td>43.682272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62892</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>Windover Lake</td>\n",
       "      <td>-74.012868</td>\n",
       "      <td>43.632478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77887</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>10.047793</td>\n",
       "      <td>93</td>\n",
       "      <td>Mink Pond</td>\n",
       "      <td>-74.128038</td>\n",
       "      <td>43.845235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50519</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>11.909968</td>\n",
       "      <td>126</td>\n",
       "      <td>Split Rock Pond</td>\n",
       "      <td>-74.153468</td>\n",
       "      <td>43.864819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Bartlett pond</td>\n",
       "      <td>-73.511126</td>\n",
       "      <td>44.106391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57554</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117</td>\n",
       "      <td>Round Pond</td>\n",
       "      <td>-73.676420</td>\n",
       "      <td>43.352455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84041 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE_SMP  temp_satellite  SITE_ID        SITE_NAME        Lon  \\\n",
       "0      1999-07-05             NaN      198    Windfall Pond -74.828821   \n",
       "63735  1999-07-05             NaN       43      Hewitt Pond -73.975033   \n",
       "63950  1999-07-05             NaN      191       South Lake -74.895066   \n",
       "4672   1999-07-05             NaN      105    Penfield Pond -73.538139   \n",
       "39192  1999-07-05             NaN      163       Carry Pond -74.488628   \n",
       "...           ...             ...      ...              ...        ...   \n",
       "62892  2023-10-15             NaN      147    Windover Lake -74.012868   \n",
       "77887  2023-10-15       10.047793       93        Mink Pond -74.128038   \n",
       "50519  2023-10-15       11.909968      126  Split Rock Pond -74.153468   \n",
       "2700   2023-10-15             NaN        5    Bartlett pond -73.511126   \n",
       "57554  2023-10-15             NaN      117       Round Pond -73.676420   \n",
       "\n",
       "             Lat  \n",
       "0      43.805388  \n",
       "63735  43.870259  \n",
       "63950  43.509919  \n",
       "4672   43.911903  \n",
       "39192  43.682272  \n",
       "...          ...  \n",
       "62892  43.632478  \n",
       "77887  43.845235  \n",
       "50519  43.864819  \n",
       "2700   44.106391  \n",
       "57554  43.352455  \n",
       "\n",
       "[84041 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ee\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "# Define the Landsat 5 bands and their corresponding standard names\n",
    "LC5_BANDS = ['ST_B6']\n",
    "LC7_BANDS = ['ST_B6']\n",
    "STD_NAMES = ['temp_satellite']\n",
    "\n",
    "\n",
    "# all_lakes=ee.FeatureCollection('projects/ee-mazarderakhsh/assets/ALAP-ALTM-Lakes-195')\n",
    "\n",
    "def maskL457sr(image):\n",
    "    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n",
    "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
    "    waterMask = image.select('QA_PIXEL').eq(5440).Or(image.select('QA_PIXEL').eq(5504))\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBand = image.select('ST_B6').multiply(0.00341802).add(-124.15)\n",
    "    return image.addBands(opticalBands, None, True).addBands(thermalBand, None, True).updateMask(qaMask).updateMask(saturationMask).updateMask(waterMask)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to compute the mean reflectance values for the specified bands within the region of interest (lake)\n",
    "def reflectance(img, lake):\n",
    "    reflectance_values = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=lake, scale=30).select(STD_NAMES)\n",
    "    return img.set('DATE_SMP', img.date().format()).set('reflectance', reflectance_values)\n",
    "\n",
    "# Initialize an empty list to store the dataframes for each lake\n",
    "dfs = []\n",
    "\n",
    "\n",
    "\n",
    "# Filter out rows with empty latitude or longitude values\n",
    "# df_coord_filtered = df_coord[(df_coord['Lat'].notnull()) & (df_coord['Lon'].notnull())]\n",
    "\n",
    "# Loop through each lake name and retrieve Landsat 5 imagery for that lake\n",
    "for i in range(lakesList.size().getInfo()):\n",
    "    lake = ee.Feature(lakesList.get(i))\n",
    "    lat = ee.Number(lake.geometry().coordinates().get(1))\n",
    "    lon = ee.Number(lake.geometry().coordinates().get(0))\n",
    "    lake_point = ee.Geometry.Point([lon, lat]).buffer(90)\n",
    "    lakeName = ee.String(lake.get('NAME')).getInfo()\n",
    "    lakeID = ee.String(lake.get('Field1')).getInfo()\n",
    "\n",
    "    lat_value = float(ee.Number(lake.geometry().coordinates().get(1)).getInfo())\n",
    "    lon_value = float(ee.Number(lake.geometry().coordinates().get(0)).getInfo())\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "    # Retrieve Landsat 7 imagery for the specific lake\n",
    "    l7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
    "        .filter(ee.Filter.calendarRange(1, 12, 'month')) \\\n",
    "        .filterBounds(lake_point) \\\n",
    "        .filter(ee.Filter.lt('CLOUD_COVER', 50)) \\\n",
    "        .map(maskL457sr) \\\n",
    "        .select(LC7_BANDS, STD_NAMES)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    # Map the reflectance function over the Landsat 5 ImageCollection for the specific lake\n",
    "    map_reflectance = l7.map(lambda img: reflectance(img, lake_point))\n",
    "\n",
    "    # Reduce the mapped image collection to get reflectance values for the specific lake\n",
    "    list_reflectance = map_reflectance.reduceColumns(ee.Reducer.toList(2), ['DATE_SMP', 'reflectance']).values().get(0)\n",
    "\n",
    "    # Convert the results to a pandas DataFrame\n",
    "    df_reflectance = pd.DataFrame(list_reflectance.getInfo(), columns=['DATE_SMP', 'reflectance'])\n",
    "    df_reflectance['DATE_SMP'] = pd.to_datetime(df_reflectance['DATE_SMP'])\n",
    "    df_reflectance['DATE_SMP'] = df_reflectance['DATE_SMP'].dt.date\n",
    "    df_reflectance['reflectance'] = df_reflectance['reflectance'].apply(lambda x: {k: v for k, v in x.items() if v is not None})\n",
    "\n",
    "    # Unpack the 'reflectance' dictionary and create separate columns for each band\n",
    "    df_reflectance = pd.concat([df_reflectance.drop('reflectance', axis=1),\n",
    "                                df_reflectance['reflectance'].apply(pd.Series).astype('float64', errors='ignore')], axis=1)\n",
    "    \n",
    "    df_reflectance['SITE_ID'] = lakeID\n",
    "    df_reflectance['SITE_NAME'] = lakeName\n",
    "    df_reflectance['Lon'] = lon_value\n",
    "    df_reflectance['Lat'] = lat_value\n",
    "\n",
    "    # Add the DataFrame to the list\n",
    "    dfs.append(df_reflectance)\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df_all_lakes_Landsat_7 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by 'DATE_SMP' in ascending order\n",
    "df_all_lakes_Landsat_7.sort_values(by='DATE_SMP', inplace=True)\n",
    "\n",
    "# df_all_lakes.dropna(inplace=True)\n",
    "df_all_lakes_Landsat_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f76bd60-7965-4ae8-ab42-3fee78988299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_23888\\2690047828.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7.dropna(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_SMP</th>\n",
       "      <th>temp_satellite</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38517</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>19.817952</td>\n",
       "      <td>80</td>\n",
       "      <td>Long Lake</td>\n",
       "      <td>-74.361967</td>\n",
       "      <td>44.040789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70353</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>19.362261</td>\n",
       "      <td>185</td>\n",
       "      <td>Otter Lake</td>\n",
       "      <td>-74.499173</td>\n",
       "      <td>43.188512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70780</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>20.801359</td>\n",
       "      <td>196</td>\n",
       "      <td>Willis Lake</td>\n",
       "      <td>-74.242343</td>\n",
       "      <td>43.369172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73240</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>15.256875</td>\n",
       "      <td>104</td>\n",
       "      <td>Paradox Lake</td>\n",
       "      <td>-73.670748</td>\n",
       "      <td>43.891645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73445</th>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>14.012138</td>\n",
       "      <td>119</td>\n",
       "      <td>Sacandaga Lake</td>\n",
       "      <td>-74.423485</td>\n",
       "      <td>43.486487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46131</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>12.579394</td>\n",
       "      <td>44</td>\n",
       "      <td>Hidden Lake</td>\n",
       "      <td>-73.762855</td>\n",
       "      <td>43.383673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>13.244898</td>\n",
       "      <td>120</td>\n",
       "      <td>Schroon Lake</td>\n",
       "      <td>-73.761745</td>\n",
       "      <td>43.823403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>9.241722</td>\n",
       "      <td>105</td>\n",
       "      <td>Penfield Pond</td>\n",
       "      <td>-73.538139</td>\n",
       "      <td>43.911903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77887</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>10.047793</td>\n",
       "      <td>93</td>\n",
       "      <td>Mink Pond</td>\n",
       "      <td>-74.128038</td>\n",
       "      <td>43.845235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50519</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>11.909968</td>\n",
       "      <td>126</td>\n",
       "      <td>Split Rock Pond</td>\n",
       "      <td>-74.153468</td>\n",
       "      <td>43.864819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38254 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE_SMP  temp_satellite  SITE_ID        SITE_NAME        Lon  \\\n",
       "38517  1999-07-05       19.817952       80        Long Lake -74.361967   \n",
       "70353  1999-07-05       19.362261      185       Otter Lake -74.499173   \n",
       "70780  1999-07-05       20.801359      196      Willis Lake -74.242343   \n",
       "73240  1999-07-05       15.256875      104     Paradox Lake -73.670748   \n",
       "73445  1999-07-05       14.012138      119   Sacandaga Lake -74.423485   \n",
       "...           ...             ...      ...              ...        ...   \n",
       "46131  2023-10-15       12.579394       44      Hidden Lake -73.762855   \n",
       "7759   2023-10-15       13.244898      120     Schroon Lake -73.761745   \n",
       "4465   2023-10-15        9.241722      105    Penfield Pond -73.538139   \n",
       "77887  2023-10-15       10.047793       93        Mink Pond -74.128038   \n",
       "50519  2023-10-15       11.909968      126  Split Rock Pond -74.153468   \n",
       "\n",
       "             Lat  \n",
       "38517  44.040789  \n",
       "70353  43.188512  \n",
       "70780  43.369172  \n",
       "73240  43.891645  \n",
       "73445  43.486487  \n",
       "...          ...  \n",
       "46131  43.383673  \n",
       "7759   43.823403  \n",
       "4465   43.911903  \n",
       "77887  43.845235  \n",
       "50519  43.864819  \n",
       "\n",
       "[38254 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates from specified columns\n",
    "df_all_lakes_Landsat_7 = df_all_lakes_Landsat_7.drop_duplicates(subset=['DATE_SMP', 'SITE_ID', 'SITE_NAME', 'Lon', 'Lat'])\n",
    "df_all_lakes_Landsat_7.dropna(inplace=True)\n",
    "\n",
    "# Now df_all_lakes_Landsat8 has duplicates removed from the specified columns\n",
    "df_all_lakes_Landsat_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db16a4e-a6ef-4323-9c23-556c9bdb52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully exported to Excel file: Landsat_7_199Lakes_4232024_WaterMask.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the file path for the Excel file\n",
    "excel_file_path = 'Landsat_7_199Lakes_4232024_WaterMask.xlsx'\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "df_all_lakes_Landsat_7.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(\"DataFrame successfully exported to Excel file:\", excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93969593-7cb6-4616-a301-e40fe55f1c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_23888\\3222914978.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_Annual_4122024_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Combine data for June, July, and August\n",
    "    summer_data = lake_data[lake_data['DATE_SMP'].dt.month.isin([1,2,3,4,5,6, 7, 8,9,10,11,12])]\n",
    "    \n",
    "    # Remove NaN or blank values from x_values and corresponding y_values\n",
    "    x_values = summer_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "    y_values = summer_data['temp_satellite'].values\n",
    "    mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "    x_values = x_values[mask]\n",
    "    y_values = y_values[mask]\n",
    "    \n",
    "    # Check if x and y contain more than one distinct value\n",
    "    if len(np.unique(x_values)) > 1:\n",
    "        slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "        \n",
    "        # Check if the trend is significant (p-value < 0.05)\n",
    "        if p_value < 0.05:\n",
    "            slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "            result = {\n",
    "                'Lake_ID': lake_id,\n",
    "                'Lake_name': pond_n,\n",
    "                'Month': 'Annual',\n",
    "                'Slope_per_Decade': slope_per_decade,\n",
    "                'P-value': p_value,\n",
    "                'R-value': r_value,\n",
    "                'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_199_Annual_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_Annual_4122024_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e456b840-54c9-4a9c-b500-02e68037fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_23888\\2018532003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_SUMMER_4122024_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Combine data for June, July, and August\n",
    "    summer_data = lake_data[lake_data['DATE_SMP'].dt.month.isin([6, 7, 8])]\n",
    "    \n",
    "    # Remove NaN or blank values from x_values and corresponding y_values\n",
    "    x_values = summer_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "    y_values = summer_data['temp_satellite'].values\n",
    "    mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "    x_values = x_values[mask]\n",
    "    y_values = y_values[mask]\n",
    "    \n",
    "    # Check if x and y contain more than one distinct value\n",
    "    if len(np.unique(x_values)) > 1:\n",
    "        slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "        \n",
    "        # Check if the trend is significant (p-value < 0.05)\n",
    "        if p_value < 0.05:\n",
    "            slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "            result = {\n",
    "                'Lake_ID': lake_id,\n",
    "                'Lake_name': pond_n,\n",
    "                'Month': 'June-August',\n",
    "                'Slope_per_Decade': slope_per_decade,\n",
    "                'P-value': p_value,\n",
    "                'R-value': r_value,\n",
    "                'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_199_SUMMER_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_SUMMER_4122024_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344052c4-8bdf-419e-ba83-5fb0cc9790a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_23888\\3646166533.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_May_November_4122024_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Combine data for June, July, and August\n",
    "    summer_data = lake_data[lake_data['DATE_SMP'].dt.month.isin([5,6, 7, 8,9,10,11])]\n",
    "    \n",
    "    # Filter out rows with NaN values\n",
    "    summer_data = summer_data.dropna(subset=['temp_satellite'])\n",
    "    \n",
    "    # Check if the data is not empty\n",
    "    if not summer_data.empty:\n",
    "        # Compute the linear regression\n",
    "        x_values = summer_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "        y_values = summer_data['temp_satellite'].values\n",
    "        \n",
    "        # Check if x and y contain more than one value\n",
    "        if len(x_values) > 1:\n",
    "            slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "            \n",
    "            # Check if the trend is significant (p-value < 0.05)\n",
    "            if p_value < 0.05:\n",
    "                slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "                result = {\n",
    "                    'Lake_ID': lake_id,\n",
    "                    'Lake_name': pond_n,\n",
    "                    'Month': 'May-November',\n",
    "                    'Slope_per_Decade': slope_per_decade,\n",
    "                    'P-value': p_value,\n",
    "                    'R-value': r_value,\n",
    "                    'Temp_satellite': y_values.mean()  # Calculate mean temperature\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_199_May_November_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_May_November_4122024_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a8dc3-b2b5-48d1-9dd2-5f2f290cbe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_23888\\291345840.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mean temperatures saved to average_mean_temps_landsat7_summer_2009_2011.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_all_lakes_Landsat5 is your DataFrame containing Landsat 5 data\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = lake_data['SITE_NAME'].iloc[0]  # Get the lake name\n",
    "    \n",
    "    # Filter data for the specified years and summer months\n",
    "    summer_data_2009_2011 = lake_data[\n",
    "        (lake_data['DATE_SMP'].dt.year >= 2009) & \n",
    "        (lake_data['DATE_SMP'].dt.year <= 2011) & \n",
    "        (lake_data['DATE_SMP'].dt.month.isin([6, 7, 8]))\n",
    "    ]\n",
    "    \n",
    "    # Calculate the average mean temperature for summer\n",
    "    average_mean_temp = summer_data_2009_2011['temp_satellite'].mean()\n",
    "    \n",
    "    # Append the result to the results list\n",
    "    results.append({\n",
    "        'Lake_ID': lake_id,\n",
    "        'Lake_name': pond_n,\n",
    "        'Average_mean_temp': average_mean_temp\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "average_temps_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "average_temps_df.to_csv('average_mean_temps_landsat7_summer_2009_2011_199LAKES_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Average mean temperatures saved to average_mean_temps_landsat7_summer_2009_2011.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "656ee8cb-a664-4948-bcc6-1aec24a9dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_23888\\947989004.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L5_1000_Monthly_4122024_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Loop over each month\n",
    "    for month in range(1, 13):\n",
    "        month_data = lake_data[lake_data['DATE_SMP'].dt.month == month]\n",
    "\n",
    "        # Remove NaN or blank values from x_values and corresponding y_values\n",
    "        x_values = month_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "        y_values = month_data['temp_satellite'].values\n",
    "        mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "        x_values = x_values[mask]\n",
    "        y_values = y_values[mask]\n",
    "\n",
    "        # Check if x and y contain more than one distinct value\n",
    "        if len(np.unique(x_values)) > 1:\n",
    "            slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "\n",
    "            # Check if the trend is significant (p-value < 0.05)\n",
    "            if p_value < 0.05:\n",
    "                slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "                result = {\n",
    "                    'Lake_ID': lake_id,\n",
    "                    'Lake_name': pond_n,\n",
    "                    'Month': month,\n",
    "                    'Slope_per_Decade': slope_per_decade,\n",
    "                    'P-value': p_value,\n",
    "                    'R-value': r_value,\n",
    "                    'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_199_Monthly_4232024_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L5_1000_Monthly_4122024_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883dabed-3a5d-489f-a1be-88e9141c94fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty\\AppData\\Local\\Temp\\ipykernel_23888\\2013635550.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to significant_slopes_L7_50_Monthly_4232024.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "df_all_lakes_Landsat_7['DATE_SMP'] = pd.to_datetime(df_all_lakes_Landsat_7['DATE_SMP'])\n",
    "\n",
    "# Loop over each lake in the DataFrame\n",
    "for lake_id, lake_data in df_all_lakes_Landsat_7.groupby('SITE_ID'):\n",
    "    pond_n = df_all_lakes_Landsat_7.loc[df_all_lakes_Landsat_7['SITE_ID'] == lake_id, 'SITE_NAME'].iloc[0]\n",
    "\n",
    "    # Loop over each month\n",
    "    for month in range(1, 13):\n",
    "        month_data = lake_data[lake_data['DATE_SMP'].dt.month == month]\n",
    "\n",
    "        # Remove NaN or blank values from x_values and corresponding y_values\n",
    "        x_values = month_data['DATE_SMP'].values.astype(np.int64) // (10 ** 9)  # Convert to seconds\n",
    "        y_values = month_data['temp_satellite'].values\n",
    "        mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "        x_values = x_values[mask]\n",
    "        y_values = y_values[mask]\n",
    "\n",
    "        # Check if x and y contain more than one distinct value\n",
    "        if len(np.unique(x_values)) > 1:\n",
    "            slope, _, r_value, p_value, _ = stats.linregress(x_values, y_values)\n",
    "\n",
    "            slope_per_decade = slope * 10 * 365 * 24 * 3600  # Convert to Â°C/decade\n",
    "            result = {\n",
    "                'Lake_ID': lake_id,\n",
    "                'Lake_name': pond_n,\n",
    "                'Month': month,\n",
    "                'Slope_per_Decade': slope_per_decade,\n",
    "                'P-value': p_value,\n",
    "                'R-value': r_value,\n",
    "                'Temp_satellite': y_values.mean()  # Calculate mean temperature for non-blank values\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('significant_slopes_L7_199_Monthly_4232024_RemovePValue_WaterMask.csv', index=False)\n",
    "\n",
    "print(\"Results saved to significant_slopes_L7_50_Monthly_4232024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcd348-27a3-4e42-a046-6cd294bcced0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
